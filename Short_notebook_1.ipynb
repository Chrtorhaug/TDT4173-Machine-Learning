{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d318c3-43e5-413f-a80e-f6e990d95179",
   "metadata": {},
   "source": [
    "##TEAM MEMBERS\n",
    "\n",
    "Aidan Stautland, 502841; Christian Torhaug, 564355; Jens Skaug, STUDID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f11a85d1-1da9-4b7c-a925-3a1b682388d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import geopandas as gpd\n",
    "from geopy.distance import geodesic\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d795c0d5-96b8-4bda-95df-a7d0df3697db",
   "metadata": {},
   "source": [
    "ais_sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52a4fcd7-0fa8-4866-ae47-b7666655e343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampledf = pd.read_csv(\"ais_sample_submission.csv\")\n",
    "\n",
    "sampledf[\"ID\"] = sampledf[\"ID\"].apply(lambda x: int(x))\n",
    "sampledf[\"latitude_predicted\"] = sampledf[\"latitude_predicted\"].apply(lambda x: float(x))\n",
    "sampledf[\"longitude_predicted\"] = sampledf[\"longitude_predicted\"].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd046a4-909a-43b6-b859-acf7fc2a3532",
   "metadata": {
    "tags": []
   },
   "source": [
    "ais_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57fb181c-5054-42eb-ad17-7c1636e87dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testdf = pd.read_csv(\"ais_test.csv\")\n",
    "\n",
    "testdf[\"time\"] = testdf[\"time\"].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\"))\n",
    "testdf[\"scaling_factor\"] = testdf[\"scaling_factor\"].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3904c6f1-ce80-42d0-ac0a-e9e06e45078b",
   "metadata": {},
   "source": [
    "ais_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10076f61-fb54-4eaf-b770-08b532f40609",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "traindf = pd.read_csv(\"~/Ais_Data/ais_train.csv\", sep=\"|\")\n",
    "\n",
    "def parseEta(row):\n",
    "    try:\n",
    "        return datetime.strptime(row['etaRaw'], \"%m-%d %H:%M\")\n",
    "    except ValueError:\n",
    "        return \"\"\n",
    "\n",
    "#traindf[\"time\"] = traindf[\"time\"].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\"))\n",
    "traindf[\"time\"] = pd.to_datetime(traindf[\"time\"]) \n",
    "traindf[\"cog\"] = traindf[\"cog\"].apply(lambda x: float(x) if float(x) < 360.0 else 360.0)\n",
    "traindf[\"sog\"] = traindf[\"sog\"].apply(lambda x: float(x) if float(x) <= 30.0 else 0)\n",
    "traindf[\"rot\"] = traindf[\"rot\"].apply(lambda x: int(x))\n",
    "traindf[\"heading\"] = traindf[\"heading\"].apply(lambda x: int(x) if int(x) < 360.0 else 360.0)\n",
    "traindf[\"etaRaw\"] = traindf.apply(parseEta, axis=1)\n",
    "traindf[\"latitude\"] = traindf[\"latitude\"].apply(lambda x: float(x))\n",
    "traindf[\"longitude\"] = traindf[\"longitude\"].apply(lambda x: float(x))\n",
    "\n",
    "traindf[\"navstat\"] = traindf[\"navstat\"].apply(lambda x: int(x) if x in [0, 1, 5, 8] else 15)\n",
    "traindf[\"navstat\"] = traindf[\"navstat\"].replace(8, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d1a308-b414-4c80-8dfa-5f241745525b",
   "metadata": {},
   "source": [
    "ports.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "300bcee3-3599-4bc4-ba72-d727fd57a984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "portsdf = pd.read_csv(\"ports.csv\", sep=\"|\")\n",
    "\n",
    "portsdf[\"latitude\"] = portsdf[\"latitude\"].apply(lambda x: float(x))\n",
    "portsdf[\"longitude\"] = portsdf[\"longitude\"].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2a5db6-3378-4561-94a1-caa76c01f806",
   "metadata": {},
   "source": [
    "schedules_to_may_2024.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c88489f0-e85d-4015-9799-d6856c59b518",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schedulesdf = pd.read_csv(\"~/Ais_Data/schedules_to_may_2024.csv\", sep=\"|\")\n",
    "schedulesdf = schedulesdf.drop_duplicates()\n",
    "schedulesdf = schedulesdf.dropna(subset=['portName'])\n",
    "\n",
    "schedulesdf[\"arrivalDate\"] = pd.to_datetime(schedulesdf[\"arrivalDate\"], errors='coerce')\n",
    "schedulesdf[\"arrivalDate\"] = schedulesdf[\"arrivalDate\"].dt.tz_convert('UTC').dt.tz_localize(None)\n",
    "schedulesdf[\"sailingDate\"] = pd.to_datetime(schedulesdf[\"sailingDate\"], errors='coerce')\n",
    "schedulesdf[\"sailingDate\"] = schedulesdf[\"sailingDate\"].dt.tz_convert('UTC').dt.tz_localize(None)\n",
    "schedulesdf[\"portLatitude\"] = schedulesdf[\"portLatitude\"].apply(lambda x: float(x))\n",
    "schedulesdf[\"portLongitude\"] = schedulesdf[\"portLongitude\"].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff9b5b2-d1d1-4bc0-98d0-452f589c1150",
   "metadata": {
    "tags": []
   },
   "source": [
    "vessels.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59d2444d-748d-4bfe-90d4-65ab5e748596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vehiclesdf = pd.read_csv(\"vessels.csv\", sep=\"|\")\n",
    "\n",
    "vehiclesdf[\"CEU\"] = vehiclesdf[\"CEU\"].apply(lambda x: int(x) if pd.notna(x) else 0)\n",
    "vehiclesdf[\"DWT\"] = vehiclesdf[\"DWT\"].apply(lambda x: int(x) if pd.notna(x) else 0)\n",
    "vehiclesdf[\"GT\"] = vehiclesdf[\"GT\"].apply(lambda x: int(x) if pd.notna(x) else 0)\n",
    "vehiclesdf[\"NT\"] = vehiclesdf[\"NT\"].apply(lambda x: int(x) if pd.notna(x) else 0)\n",
    "vehiclesdf[\"vesselType\"] = vehiclesdf[\"vesselType\"].apply(lambda x: int(x) if pd.notna(x) else 0)\n",
    "vehiclesdf[\"breadth\"] = vehiclesdf[\"breadth\"].apply(lambda x: float(x) if pd.notna(x) else 0)\n",
    "vehiclesdf[\"depth\"] = vehiclesdf[\"depth\"].apply(lambda x: float(x) if pd.notna(x) else 0)\n",
    "vehiclesdf[\"draft\"] = vehiclesdf[\"draft\"].apply(lambda x: float(x) if pd.notna(x) else 0)\n",
    "vehiclesdf[\"enginePower\"] = vehiclesdf[\"enginePower\"].apply(lambda x: float(x) if pd.notna(x) else 0)\n",
    "vehiclesdf[\"freshWater\"] = vehiclesdf[\"freshWater\"].apply(lambda x: float(x) if pd.notna(x) else 0)\n",
    "vehiclesdf[\"fuel\"] = vehiclesdf[\"fuel\"].apply(lambda x: float(x) if pd.notna(x) else 0)\n",
    "vehiclesdf[\"length\"] = vehiclesdf[\"length\"].apply(lambda x: float(x) if pd.notna(x) else 0)\n",
    "vehiclesdf[\"maxHeight\"] = vehiclesdf[\"maxHeight\"].apply(lambda x: float(x) if pd.notna(x) else 0)\n",
    "vehiclesdf[\"maxSpeed\"] = vehiclesdf[\"maxSpeed\"].apply(lambda x: float(x) if pd.notna(x) else 0)\n",
    "vehiclesdf[\"maxWidth\"] = vehiclesdf[\"maxWidth\"].apply(lambda x: float(x) if pd.notna(x) else 0)\n",
    "vehiclesdf[\"rampCapacity\"] = vehiclesdf[\"rampCapacity\"].apply(lambda x: float(x) if pd.notna(x) else 0)\n",
    "vehiclesdf[\"yearBuilt\"] = vehiclesdf[\"yearBuilt\"].apply(lambda x: datetime.strptime(str(x), \"%Y\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5105661-a278-4644-8f38-68ea007b3627",
   "metadata": {},
   "source": [
    "Function for calculating time difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34db8edf-203d-415b-afc7-3cd425e4dda4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def timeDiff(t1: datetime, t2: datetime, i=\"s\"):\n",
    "    diff = t1 - t2 if t1 >= t2  else t2 - t1\n",
    "    if i == \"s\":\n",
    "        return diff.total_seconds()\n",
    "    elif i == \"m\":\n",
    "        return diff.total_seconds() // 60\n",
    "    elif i == \"h\":\n",
    "        return diff.total_seconds() // 3600\n",
    "    elif i == \"d\":\n",
    "        return diff.days\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dce401-48f3-416d-bfdf-3b0b3bdd2222",
   "metadata": {
    "tags": []
   },
   "source": [
    "Adding WORKING_SIZE previous nodes to the ais_train dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5744bef-e36d-4eba-99a2-3bd08be69135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prev_nodes_train(traindf: pd.DataFrame, WINDOW_SIZE=1):\n",
    "    for j in range(1, WINDOW_SIZE + 1):\n",
    "        traindf[f'latitude_{j}'] = traindf.groupby('vesselId')['latitude'].shift(j)\n",
    "        traindf[f'longitude_{j}'] = traindf.groupby('vesselId')['longitude'].shift(j)\n",
    "        traindf[f'cog_{j}'] = traindf.groupby('vesselId')['cog'].shift(j)\n",
    "        traindf[f'sog_{j}'] = traindf.groupby('vesselId')['sog'].shift(j)\n",
    "        \n",
    "        traindf[f'time_{j}'] = traindf.groupby('vesselId')['time'].shift(j)\n",
    "        traindf[f'time_{j}'] = (traindf['time'] - traindf[f'time_{j}']).dt.total_seconds()\n",
    "    return traindf\n",
    "\n",
    "def prev_nodes_test(traindf: pd.DataFrame, testdf: pd.DataFrame, WINDOW_SIZE=1):\n",
    "    grouped_train = traindf.groupby('vesselId')\n",
    "    \n",
    "    for j in range(1, WINDOW_SIZE + 1):\n",
    "        testdf[f'latitude_{j}'] = None\n",
    "        testdf[f'longitude_{j}'] = None\n",
    "        testdf[f'cog_{j}'] = None\n",
    "        testdf[f'sog_{j}'] = None\n",
    "        testdf[f'time_{j}'] = None\n",
    "\n",
    "    for vesselId, test_vessel_data in testdf.groupby('vesselId'):\n",
    "        if vesselId in grouped_train.groups:\n",
    "            train_vessel_data = grouped_train.get_group(vesselId)\n",
    "            for j in range(1, WINDOW_SIZE + 1):\n",
    "                if len(train_vessel_data) >= j:\n",
    "                    train_row = train_vessel_data.iloc[-j]\n",
    "                    testdf.loc[test_vessel_data.index, f'latitude_{j}'] = train_row['latitude']\n",
    "                    testdf.loc[test_vessel_data.index, f'longitude_{j}'] = train_row['longitude']\n",
    "                    testdf.loc[test_vessel_data.index, f'cog_{j}'] = train_row['cog']\n",
    "                    testdf.loc[test_vessel_data.index, f'sog_{j}'] = train_row['sog']\n",
    "                    testdf.loc[test_vessel_data.index, f'time_{j}'] = (testdf.loc[test_vessel_data.index, 'time'] - train_row['time']).dt.total_seconds()\n",
    "    return testdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06055e33-ff33-4864-b0ca-124912b8ac4e",
   "metadata": {},
   "source": [
    "Checking if a boat is on a schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "185b1c6a-0e42-4964-8627-75b8e20bc58d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['shippingLineId', 'shippingLineName', 'arrivalDate', 'sailingDate',\n",
      "       'portName', 'portId', 'portLatitude', 'portLongitude'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of ['vesselId'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_42587/3852923105.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching_schedules\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmatching_schedules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mschedulesdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedulesdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vesselId'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mtestdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"onSchedule\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0monSchedule_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedulesdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vesselId\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   5855\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5856\u001b[0m                         \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5859\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5862\u001b[0m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['vesselId'] are in the columns\""
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "def onSchedule(schedulesdf: pd.DataFrame, vesselId: str, time: datetime):\n",
    "    if schedulesdf.index.name != 'vesselId':\n",
    "        schedulesdf = schedulesdf.set_index('vesselId')\n",
    "        \n",
    "    if vesselId in schedulesdf.index:\n",
    "        vessel_schedules = schedulesdf.loc[vesselId]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    fitting_schedules = (vessel_schedules[\"sailingDate\"] >= time) & (vessel_schedules[\"arrivalDate\"] <= time)\n",
    "    if fitting_schedules.any():\n",
    "        matching_schedules = vessel_schedules.loc[fitting_schedules]\n",
    "        if len(matching_schedules) == 1:\n",
    "            return matching_schedules.iloc[0]\n",
    "    return None\n",
    "\"\"\"\n",
    "print(schedulesdf.columns)\n",
    "if schedulesdf.index.name != 'vesselId':\n",
    "    schedulesdf = schedulesdf.set_index('vesselId')\n",
    "\n",
    "def onSchedule_optimized(testdf: pd.DataFrame, schedulesdf: pd.DataFrame, vesselId: str, time: datetime):\n",
    "    if vesselId in schedulesdf.index:\n",
    "        vessel_schedules = schedulesdf.loc[vesselId]\n",
    "        if isinstance(vessel_schedules, pd.Series):\n",
    "            vessel_schedules = vessel_schedules.to_frame().T\n",
    "            \n",
    "        fitting_schedules = (vessel_schedules[\"sailingDate\"] >= time) & (vessel_schedules[\"arrivalDate\"] <= time)\n",
    "        if fitting_schedules.any():\n",
    "            matching_schedules = vessel_schedules.loc[fitting_schedules]\n",
    "            if len(matching_schedules) == 1:\n",
    "                return matching_schedules.iloc[0]\n",
    "    return None\n",
    "print(schedulesdf.columns)\n",
    "schedulesdf = schedulesdf.set_index('vesselId')\n",
    "testdf[\"onSchedule\"] = testdf.apply(lambda row: onSchedule_optimized(testdf, schedulesdf, row[\"vesselId\"], row[\"time\"]))\n",
    "print(testdf.loc[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96633d29-9ce0-4060-9cc9-eff982eea98b",
   "metadata": {},
   "source": [
    "Finding Last Data Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddc2812e-2abf-4619-aacb-938165412480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lastData(testdf: pd.DataFrame, traindf: pd.DataFrame):\n",
    "    vessels = testdf[\"vesselId\"].unique().tolist()\n",
    "    indexes = []\n",
    "\n",
    "    for v in vessels:\n",
    "        vessel_data = traindf[traindf['vesselId'] == v]\n",
    "        indexes.append(vessel_data.sort_values(by=\"time\").iloc[-1].name)\n",
    "\n",
    "    return traindf.loc[indexes].sort_values(by=\"time\")\n",
    "\n",
    "#print(lastData(testdf, traindf).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e461f805-8291-48a6-b800-e72ebe159585",
   "metadata": {},
   "source": [
    "Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1618a4fe-3d76-4e4a-ae3e-b518e2064085",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def distance(lat1, long1, lat2, long2):\n",
    "    return geodesic((lat1, long1), (lat2, long2)).meters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6668924-93ec-41a1-8fbe-12102f16583d",
   "metadata": {},
   "source": [
    "Checking if a vessel is near a port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93155d30-5d40-4c77-aee4-78936e619b68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "PORT_DIST_THRESH = 3000\n",
    "\n",
    "ports_coords = portsdf[[\"latitude\", \"longitude\"]].values\n",
    "kdtree = KDTree(ports_coords, leaf_size=30)\n",
    "\n",
    "def nearPort(portsdf: pd.DataFrame, lat, long):\n",
    "    rough_dist = PORT_DIST_THRESH / 100000\n",
    "    indices = kdtree.query_radius([[lat, long]], r=rough_dist)\n",
    "    for i in indices[0]:\n",
    "        port = portsdf.iloc[i]\n",
    "        if distance(lat, long ,port[\"latitude\"],port[\"longitude\"]) <= PORT_DIST_THRESH:\n",
    "            return port\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a0156e-82df-41f5-91b2-43d66d97cdbd",
   "metadata": {},
   "source": [
    "Checking if a vessel is far from land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f998c34a-0539-466d-a918-c6f3eedcf6c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAP_LAND_PATH = \"~/datasets/ne_10m_land.zip\"\n",
    "MAP_OCEAN_PATH = \"~/datasets/ne_10m_ocean.zip\"\n",
    "    \n",
    "land_world = gpd.read_file(MAP_LAND_PATH)\n",
    "ocean_world = gpd.read_file(MAP_OCEAN_PATH)\n",
    "\n",
    "def farFromCoast(latitude, longitude, land_world=land_world, thresh=12):\n",
    "    land_world_projected = land_world.to_crs(epsg=3857)\n",
    "    point = gpd.GeoSeries([Point(longitude, latitude)], crs=\"EPSG:4326\").to_crs(epsg=3857)\n",
    "    \n",
    "    if land_world_projected.contains(point.iloc[0]).any():\n",
    "        return False\n",
    "    \n",
    "    land_boundary = land_world_projected.geometry.boundary.unary_union\n",
    "    distanceToCoast = point.distance(land_boundary)\n",
    "    distanceNM = distanceToCoast.min() / 1852\n",
    "    \n",
    "    return distanceNM > thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375d0344-3441-4f64-89e8-328fe462a8a1",
   "metadata": {},
   "source": [
    "Calculating average SOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4966acc-484f-4743-8b43-1785424e6f9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def avgSOG(traindf: pd.DataFrame):\n",
    "    filtered_df = traindf[traindf[\"navstat\"] == 0]\n",
    "    sog_means = filtered_df.groupby(\"vesselId\")[\"sog\"].mean()\n",
    "    return sog_means.to_dict()\n",
    "\n",
    "avg = avgSOG(traindf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9e4163-f3e9-44e0-b869-ff5522cdfbbe",
   "metadata": {},
   "source": [
    "Update Navstat for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e17d59b8-43a6-43a4-be00-88df7e6070e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def updateNavStat(traindf: pd.DataFrame, testdf: pd.DataFrame, schedulesdf: pd.DataFrame):\n",
    "    statuses = ['Under_Way', 'Anchored', 'Moored']\n",
    "    for status in statuses:\n",
    "        testdf[status] = False\n",
    "\n",
    "    grouped_train = traindf.groupby('vesselId')\n",
    "    for vesselId, test_vessel_data in testdf.groupby('vesselId'):\n",
    "        if vesselId in grouped_train.groups:\n",
    "            last_train_row = grouped_train.get_group(vesselId).iloc[-1]\n",
    "            for status in statuses:\n",
    "                testdf.loc[test_vessel_data.index, status] = last_train_row[status]\n",
    "                if last_train_row[status] is True:\n",
    "                    testdf.loc[test_vessel_data.index, [s for s in statuses if s != status]] = False\n",
    "        \"\"\"for idx, row in test_vessel_data.iterrows():\n",
    "            if onSchedule(schedulesdf, vesselId, row['time']) is not None:\n",
    "                testdf.loc[idx, 'Moored'] = True\n",
    "                testdf.loc[idx, 'Under_Way'] = False\n",
    "                testdf.loc[idx, 'Anchored'] = False \"\"\"\n",
    "    return testdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a20ca6-4d05-477a-9f61-f3ac18c54a86",
   "metadata": {
    "tags": []
   },
   "source": [
    "Creating Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "851ed9ef-f459-479e-a9a4-209d8214ad73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def submission(sampledf: pd.DataFrame, lat_pred, lon_pred, deliver=False, name=\"SampleTest\") -> pd.DataFrame:\n",
    "    sample = sampledf.copy()\n",
    "\n",
    "    for i in range(len(lat_pred)):\n",
    "        sample.loc[i,\"longitude_predicted\"], sample.loc[i, \"latitude_predicted\"] = lon_pred[i], lat_pred[i]\n",
    "    \n",
    "    if deliver:\n",
    "        sample.to_csv(name + \".csv\", index=False)\n",
    "        \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c3b6f4-8d83-4adf-a05d-014a539a8b4c",
   "metadata": {},
   "source": [
    "Copying Test and Train Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec8cb495-9a9c-4235-b1ca-9394a08b03f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainRFR = traindf.copy()\n",
    "testRFR = testdf.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c6fea4-e22e-4f47-8b2d-32c1c71373de",
   "metadata": {},
   "source": [
    "Splitting data for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8c08fa7-4c3d-4535-8a97-f3c0e3040284",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vessels = trainRFR[\"vesselId\"].unique().tolist()\n",
    "vessel_dict = {vessel: i for i, vessel in enumerate(vessels)}\n",
    "\n",
    "ports = portsdf[\"portId\"].unique().tolist()\n",
    "port_dict = {port: i for i, port in enumerate(ports)}\n",
    "\n",
    "# Adding previous nodes\n",
    "window_size = 2\n",
    "trainRFR = prev_nodes_train(trainRFR, window_size)\n",
    "testRFR = prev_nodes_test(trainRFR, testRFR, window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349114d3-78a0-4202-a0af-aad4445df26c",
   "metadata": {},
   "source": [
    "ML Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9632b87c-dbab-4ae7-a89e-9fda971fe57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model without Feature Engineering\n",
      "Mean Squared Error (MSE): 1.0404\n",
      "Mean Absolute Error (MAE): 0.0596\n",
      "R^2 Score: 0.9980\n",
      "Random Forest Model without Feature Engineering\n",
      "Mean Squared Error (MSE): 9.4084\n",
      "Mean Absolute Error (MAE): 0.1177\n",
      "R^2 Score: 0.9980\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def evaluate_result(y_test, y_pred):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "    print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
    "    print(f'R^2 Score: {r2:.4f}')\n",
    "\n",
    "y_lat = trainRFR[\"latitude\"].copy()\n",
    "y_lon = trainRFR[\"longitude\"].copy()\n",
    "X = trainRFR.drop(columns=['latitude', 'longitude'])\n",
    "\n",
    "X = X.drop(columns=[\"etaRaw\", \"portId\", \"cog\", \"sog\", \"rot\", \"heading\"])\n",
    "#X[\"time\"] = X[\"time\"].astype(\"int64\") / 10**9\n",
    "X[\"time\"] = pd.to_numeric(X[\"time\"], errors='coerce')\n",
    "\n",
    "# Splitting Navstat\n",
    "X = pd.get_dummies(X, columns=[\"navstat\"], prefix=\"\", prefix_sep=\"\")\n",
    "X.rename(columns={\"0\": \"Under_Way\", \"1\": \"Anchored\", \"5\": \"Moored\"}, inplace=True)\n",
    "X = X.drop(columns=[\"15\"])\n",
    "\n",
    "X[\"avgSOG\"] = X[\"vesselId\"].apply(lambda x: avg.get(x))\n",
    "X[\"vesselId\"] = X[\"vesselId\"].map(vessel_dict)\n",
    "\n",
    "X_train, X_test, y_train_lat, y_test_lat = train_test_split(X, y_lat, test_size=0.2)\n",
    "\n",
    "clf_lat = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "clf_lat.fit(X_train, y_train_lat)\n",
    "y_pred_lat = clf_lat.predict(X_test)\n",
    "\n",
    "print('Random Forest Model without Feature Engineering')\n",
    "evaluate_result(y_test_lat, y_pred_lat)\n",
    "\n",
    "#print(y_test_lat.tolist()[:10])\n",
    "#print(y_pred_lat[:10])\n",
    "\n",
    "X_train, X_test, y_train_lon, y_test_lon = train_test_split(X, y_lon, test_size=0.2)\n",
    "\n",
    "#print(X_test.head())\n",
    "clf_lon = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "clf_lon.fit(X_train, y_train_lon)\n",
    "y_pred_lon = clf_lon.predict(X_test)\n",
    "\n",
    "print('Random Forest Model without Feature Engineering')\n",
    "evaluate_result(y_test_lon, y_pred_lon)\n",
    "\n",
    "#print(y_test_lon.tolist()[:10])\n",
    "#print(y_pred_lon[:10])\n",
    "\n",
    "#testRFR[\"nearPort\"] = None\n",
    "#testRFR[\"Under_Way\"] = None\n",
    "#testRFR[\"Anchored\"] = None\n",
    "#testRFR[\"Moored\"] = None\n",
    "\n",
    "test = testRFR.drop(columns=['ID', 'scaling_factor'])\n",
    "\n",
    "test[\"vesselId\"] = test[\"vesselId\"].map(vessel_dict)\n",
    "test = updateNavStat(X, test, schedulesdf)\n",
    "\n",
    "test[\"avgSOG\"] = test[\"vesselId\"].apply(lambda x: avg.get(x))\n",
    "\n",
    "#test[\"time\"] = test[\"time\"].astype(\"int64\") / 10**9\n",
    "test[\"time\"] = pd.to_numeric(test[\"time\"], errors='coerce')\n",
    "\n",
    "cols = test.columns.tolist()\n",
    "time_index = cols.index('time')\n",
    "vesselId_index = cols.index('vesselId')\n",
    "cols[time_index], cols[vesselId_index] = cols[vesselId_index], cols[time_index]\n",
    "test = test[cols]\n",
    "\n",
    "#print(testRFR.head())\n",
    "#print(test.head())\n",
    "\n",
    "lat_pred = clf_lat.predict(test)\n",
    "lon_pred = clf_lon.predict(test)\n",
    "\n",
    "#submission(sampledf, lat_pred, lon_pred, True, \"Test1\")\n",
    "#print(lat_pred)\n",
    "#print(lon_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4285cff-7e80-4689-92dd-9b091312a43e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>longitude_predicted</th>\n",
       "      <th>latitude_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-81.497905</td>\n",
       "      <td>31.146487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>120.296297</td>\n",
       "      <td>14.816909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10.809007</td>\n",
       "      <td>38.335911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>172.835428</td>\n",
       "      <td>-43.537958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-6.159701</td>\n",
       "      <td>48.550942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51734</th>\n",
       "      <td>51734</td>\n",
       "      <td>-31.899401</td>\n",
       "      <td>39.395808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51735</th>\n",
       "      <td>51735</td>\n",
       "      <td>-113.742467</td>\n",
       "      <td>27.983676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51736</th>\n",
       "      <td>51736</td>\n",
       "      <td>-113.830540</td>\n",
       "      <td>27.371876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51737</th>\n",
       "      <td>51737</td>\n",
       "      <td>17.450312</td>\n",
       "      <td>55.926400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51738</th>\n",
       "      <td>51738</td>\n",
       "      <td>-41.628289</td>\n",
       "      <td>55.486381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51739 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  longitude_predicted  latitude_predicted\n",
       "0          0           -81.497905           31.146487\n",
       "1          1           120.296297           14.816909\n",
       "2          2            10.809007           38.335911\n",
       "3          3           172.835428          -43.537958\n",
       "4          4            -6.159701           48.550942\n",
       "...      ...                  ...                 ...\n",
       "51734  51734           -31.899401           39.395808\n",
       "51735  51735          -113.742467           27.983676\n",
       "51736  51736          -113.830540           27.371876\n",
       "51737  51737            17.450312           55.926400\n",
       "51738  51738           -41.628289           55.486381\n",
       "\n",
       "[51739 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submission(sampledf, lat_pred, lon_pred, True, \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba2329a5-2ee9-488c-bbca-d234e13b4b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCatB = traindf.copy()\n",
    "testCatB = testdf.copy()\n",
    "\n",
    "window_size = 2\n",
    "trainCatB = prev_nodes_train(trainCatB, window_size)\n",
    "testCatB = prev_nodes_test(trainCatB, testCatB, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86ae44c9-f560-4bc1-a035-e7ebb60f210f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom catboost import CatBoostRegressor\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\\n\\ny_lat = trainCatB[\"latitude\"].copy()\\ny_lon = trainCatB[\"longitude\"].copy()\\n\\nX = trainCatB.drop(columns=[\\'latitude\\', \\'longitude\\', \\'etaRaw\\', \\'portId\\', \\'cog\\', \\'sog\\', \\'rot\\', \\'heading\\'])\\n\\nX[\"time\"] = pd.to_numeric(X[\"time\"], errors=\\'coerce\\')\\n\\nX = pd.get_dummies(X, columns=[\"navstat\"], prefix=\"\", prefix_sep=\"\")\\nX.rename(columns={\"0\": \"Under_Way\", \"1\": \"Anchored\", \"5\": \"Moored\"}, inplace=True)\\nX = X.drop(columns=[\"15\"])\\n\\nX[\"avgSOG\"] = X[\"vesselId\"].apply(lambda x: avg.get(x))\\nX[\"vesselId\"] = X[\"vesselId\"].map(vessel_dict)\\n\\nX_train_lat, X_test_lat, y_train_lat, y_test_lat = train_test_split(X, y_lat, test_size=0.2, random_state=42)\\nX_train_lon, X_test_lon, y_train_lon, y_test_lon = train_test_split(X, y_lon, test_size=0.2, random_state=42)\\n\\n# Initialize CatBoost Regressor with default parameters\\ncategorical_features = [\\'vesselId\\', \\'Under_Way\\', \\'Anchored\\', \\'Moored\\']\\ncatboost_lat = CatBoostRegressor(loss_function=\\'RMSE\\', cat_features=categorical_features, verbose=100)\\n\\n# Define parameter grid for hyperparameter tuning\\nparam_grid = {\\n    \\'iterations\\': [200, 500, 1000],\\n    \\'depth\\': [4, 6, 8],\\n    \\'learning_rate\\': [0.01, 0.05, 0.1],\\n    \\'l2_leaf_reg\\': [3, 5, 7],\\n    \\'random_strength\\': [1, 2, 5]\\n}\\n\\n# Hyperparameter tuning with GridSearchCV for latitude\\ngrid_search_lat = GridSearchCV(estimator=catboost_lat, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\\ngrid_search_lat.fit(X_train_lat, y_train_lat)\\nbest_params_lat = grid_search_lat.best_params_\\nprint(f\"Best parameters for latitude prediction: {best_params_lat}\")\\n\\n# Train the CatBoost model using the best parameters for latitude\\ncatboost_lat_best = CatBoostRegressor(cat_features=categorical_features, **best_params_lat, verbose=100)\\ncatboost_lat_best.fit(X_train_lat, y_train_lat)\\n\\n# Hyperparameter tuning with GridSearchCV for longitude\\ncatboost_lon = CatBoostRegressor(loss_function=\\'RMSE\\', cat_features=categorical_features, verbose=100)\\ngrid_search_lon = GridSearchCV(estimator=catboost_lon, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\\ngrid_search_lon.fit(X_train_lon, y_train_lon)\\nbest_params_lon = grid_search_lon.best_params_\\nprint(f\"Best parameters for longitude prediction: {best_params_lon}\")\\n\\n# Train the CatBoost model using the best parameters for longitude\\ncatboost_lon_best = CatBoostRegressor(cat_features=categorical_features, **best_params_lon, verbose=100)\\ncatboost_lon_best.fit(X_train_lon, y_train_lon)\\n\\n# Step 7: Evaluate the models\\ndef evaluate_result(y_test, y_pred):\\n    mse = mean_squared_error(y_test, y_pred)\\n    mae = mean_absolute_error(y_test, y_pred)\\n    r2 = r2_score(y_test, y_pred)\\n    print(f\\'Mean Squared Error (MSE): {mse:.4f}\\')\\n    print(f\\'Mean Absolute Error (MAE): {mae:.4f}\\')\\n    print(f\\'R^2 Score: {r2:.4f}\\')\\n\\n# Latitude predictions\\ny_pred_lat = catboost_lat_best.predict(X_test_lat)\\nprint(\\'CatBoost Latitude Prediction Results:\\')\\nevaluate_result(y_test_lat, y_pred_lat)\\n\\n# Longitude predictions\\ny_pred_lon = catboost_lon_best.predict(X_test_lon)\\nprint(\\'CatBoost Longitude Prediction Results:\\')\\nevaluate_result(y_test_lon, y_pred_lon)\\n\\ntest = testCatB.drop(columns=[\\'ID\\', \\'scaling_factor\\'])\\n\\ntest[\"vesselId\"] = test[\"vesselId\"].map(vessel_dict)\\ntest = updateNavStat(X, test, schedulesdf)\\n\\ntest[\"avgSOG\"] = test[\"vesselId\"].apply(lambda x: avg.get(x))\\ntest[\"time\"] = pd.to_numeric(test[\"time\"], errors=\\'coerce\\')\\n\\ncols = test.columns.tolist()\\ntime_index = cols.index(\\'time\\')\\nvesselId_index = cols.index(\\'vesselId\\')\\ncols[time_index], cols[vesselId_index] = cols[vesselId_index], cols[time_index]\\ntest = test[cols]\\n\\n# Step 8: Final predictions on test set and submission creation\\nlat_pred = catboost_lat_best.predict(test)\\nlon_pred = catboost_lon_best.predict(test)\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "y_lat = trainCatB[\"latitude\"].copy()\n",
    "y_lon = trainCatB[\"longitude\"].copy()\n",
    "\n",
    "X = trainCatB.drop(columns=['latitude', 'longitude', 'etaRaw', 'portId', 'cog', 'sog', 'rot', 'heading'])\n",
    "\n",
    "X[\"time\"] = pd.to_numeric(X[\"time\"], errors='coerce')\n",
    "\n",
    "X = pd.get_dummies(X, columns=[\"navstat\"], prefix=\"\", prefix_sep=\"\")\n",
    "X.rename(columns={\"0\": \"Under_Way\", \"1\": \"Anchored\", \"5\": \"Moored\"}, inplace=True)\n",
    "X = X.drop(columns=[\"15\"])\n",
    "\n",
    "X[\"avgSOG\"] = X[\"vesselId\"].apply(lambda x: avg.get(x))\n",
    "X[\"vesselId\"] = X[\"vesselId\"].map(vessel_dict)\n",
    "\n",
    "X_train_lat, X_test_lat, y_train_lat, y_test_lat = train_test_split(X, y_lat, test_size=0.2, random_state=42)\n",
    "X_train_lon, X_test_lon, y_train_lon, y_test_lon = train_test_split(X, y_lon, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize CatBoost Regressor with default parameters\n",
    "categorical_features = ['vesselId', 'Under_Way', 'Anchored', 'Moored']\n",
    "catboost_lat = CatBoostRegressor(loss_function='RMSE', cat_features=categorical_features, verbose=100)\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'iterations': [200, 500, 1000],\n",
    "    'depth': [4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'l2_leaf_reg': [3, 5, 7],\n",
    "    'random_strength': [1, 2, 5]\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning with GridSearchCV for latitude\n",
    "grid_search_lat = GridSearchCV(estimator=catboost_lat, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search_lat.fit(X_train_lat, y_train_lat)\n",
    "best_params_lat = grid_search_lat.best_params_\n",
    "print(f\"Best parameters for latitude prediction: {best_params_lat}\")\n",
    "\n",
    "# Train the CatBoost model using the best parameters for latitude\n",
    "catboost_lat_best = CatBoostRegressor(cat_features=categorical_features, **best_params_lat, verbose=100)\n",
    "catboost_lat_best.fit(X_train_lat, y_train_lat)\n",
    "\n",
    "# Hyperparameter tuning with GridSearchCV for longitude\n",
    "catboost_lon = CatBoostRegressor(loss_function='RMSE', cat_features=categorical_features, verbose=100)\n",
    "grid_search_lon = GridSearchCV(estimator=catboost_lon, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search_lon.fit(X_train_lon, y_train_lon)\n",
    "best_params_lon = grid_search_lon.best_params_\n",
    "print(f\"Best parameters for longitude prediction: {best_params_lon}\")\n",
    "\n",
    "# Train the CatBoost model using the best parameters for longitude\n",
    "catboost_lon_best = CatBoostRegressor(cat_features=categorical_features, **best_params_lon, verbose=100)\n",
    "catboost_lon_best.fit(X_train_lon, y_train_lon)\n",
    "\n",
    "# Step 7: Evaluate the models\n",
    "def evaluate_result(y_test, y_pred):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "    print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
    "    print(f'R^2 Score: {r2:.4f}')\n",
    "\n",
    "# Latitude predictions\n",
    "y_pred_lat = catboost_lat_best.predict(X_test_lat)\n",
    "print('CatBoost Latitude Prediction Results:')\n",
    "evaluate_result(y_test_lat, y_pred_lat)\n",
    "\n",
    "# Longitude predictions\n",
    "y_pred_lon = catboost_lon_best.predict(X_test_lon)\n",
    "print('CatBoost Longitude Prediction Results:')\n",
    "evaluate_result(y_test_lon, y_pred_lon)\n",
    "\n",
    "test = testCatB.drop(columns=['ID', 'scaling_factor'])\n",
    "\n",
    "test[\"vesselId\"] = test[\"vesselId\"].map(vessel_dict)\n",
    "test = updateNavStat(X, test, schedulesdf)\n",
    "\n",
    "test[\"avgSOG\"] = test[\"vesselId\"].apply(lambda x: avg.get(x))\n",
    "test[\"time\"] = pd.to_numeric(test[\"time\"], errors='coerce')\n",
    "\n",
    "cols = test.columns.tolist()\n",
    "time_index = cols.index('time')\n",
    "vesselId_index = cols.index('vesselId')\n",
    "cols[time_index], cols[vesselId_index] = cols[vesselId_index], cols[time_index]\n",
    "test = test[cols]\n",
    "\n",
    "# Step 8: Final predictions on test set and submission creation\n",
    "lat_pred = catboost_lat_best.predict(test)\n",
    "lon_pred = catboost_lon_best.predict(test)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff26c592-cebf-44f2-b45f-219454d981d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "0:\tlearn: 20.7218494\ttotal: 117ms\tremaining: 11.6s\n",
      "99:\tlearn: 1.3956507\ttotal: 17.9s\tremaining: 0us\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=7, learning_rate=0.1, random_strength=1; total time=  32.0s\n",
      "0:\tlearn: 20.7637504\ttotal: 330ms\tremaining: 2m 44s\n",
      "100:\tlearn: 1.3106280\ttotal: 34.6s\tremaining: 2m 16s\n",
      "200:\tlearn: 1.0831108\ttotal: 1m 8s\tremaining: 1m 41s\n",
      "300:\tlearn: 0.9745827\ttotal: 1m 41s\tremaining: 1m 6s\n",
      "400:\tlearn: 0.8994724\ttotal: 2m 14s\tremaining: 33.1s\n",
      "499:\tlearn: 0.8406887\ttotal: 2m 46s\tremaining: 0us\n",
      "[CV] END depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.1, random_strength=5; total time= 3.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 20.7216246\ttotal: 193ms\tremaining: 19.2s\n",
      "99:\tlearn: 1.3875740\ttotal: 17.6s\tremaining: 0us\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=3, learning_rate=0.1, random_strength=1; total time=  31.8s\n",
      "0:\tlearn: 20.7641282\ttotal: 417ms\tremaining: 3m 28s\n",
      "100:\tlearn: 1.2796485\ttotal: 34.2s\tremaining: 2m 15s\n",
      "200:\tlearn: 1.0735237\ttotal: 1m 8s\tremaining: 1m 41s\n",
      "300:\tlearn: 0.9722561\ttotal: 1m 41s\tremaining: 1m 7s\n",
      "400:\tlearn: 0.9081901\ttotal: 2m 15s\tremaining: 33.5s\n",
      "499:\tlearn: 0.8537098\ttotal: 2m 47s\tremaining: 0us\n",
      "[CV] END depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.1, random_strength=5; total time= 3.1min\n",
      "0:\tlearn: 20.7202494\ttotal: 233ms\tremaining: 23.1s\n",
      "99:\tlearn: 1.3779422\ttotal: 17.9s\tremaining: 0us\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=7, learning_rate=0.1, random_strength=1; total time=  32.1s\n",
      "0:\tlearn: 20.7070827\ttotal: 398ms\tremaining: 3m 18s\n",
      "100:\tlearn: 1.1203228\ttotal: 46.1s\tremaining: 3m 2s\n",
      "200:\tlearn: 0.9254617\ttotal: 1m 31s\tremaining: 2m 15s\n",
      "300:\tlearn: 0.8166268\ttotal: 2m 15s\tremaining: 1m 29s\n",
      "400:\tlearn: 0.7329574\ttotal: 2m 56s\tremaining: 43.5s\n",
      "499:\tlearn: 0.6809691\ttotal: 3m 35s\tremaining: 0us\n",
      "[CV] END depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.1, random_strength=2; total time= 3.9min\n",
      "0:\tlearn: 20.7200198\ttotal: 312ms\tremaining: 30.9s\n",
      "99:\tlearn: 1.3628612\ttotal: 18s\tremaining: 0us\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=3, learning_rate=0.1, random_strength=1; total time=  32.1s\n",
      "0:\tlearn: 20.7077203\ttotal: 456ms\tremaining: 3m 47s\n",
      "100:\tlearn: 1.1458487\ttotal: 45.9s\tremaining: 3m 1s\n",
      "200:\tlearn: 0.9238499\ttotal: 1m 30s\tremaining: 2m 15s\n",
      "300:\tlearn: 0.8062901\ttotal: 2m 15s\tremaining: 1m 29s\n",
      "400:\tlearn: 0.7207472\ttotal: 2m 56s\tremaining: 43.6s\n",
      "499:\tlearn: 0.6571423\ttotal: 3m 35s\tremaining: 0us\n",
      "[CV] END depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.1, random_strength=2; total time= 3.9min\n",
      "0:\tlearn: 20.6914188\ttotal: 317ms\tremaining: 2m 37s\n",
      "100:\tlearn: 1.1282709\ttotal: 22.3s\tremaining: 1m 28s\n",
      "200:\tlearn: 0.9498708\ttotal: 45.1s\tremaining: 1m 7s\n",
      "300:\tlearn: 0.8485630\ttotal: 1m 6s\tremaining: 44.2s\n",
      "400:\tlearn: 0.7854087\ttotal: 1m 28s\tremaining: 21.9s\n",
      "499:\tlearn: 0.7340948\ttotal: 1m 50s\tremaining: 0us\n",
      "Best parameters for latitude prediction: {'random_strength': 2, 'learning_rate': 0.1, 'l2_leaf_reg': 5, 'iterations': 500, 'depth': 8}\n",
      "0:\tlearn: 20.6914188\ttotal: 265ms\tremaining: 2m 12s\n",
      "100:\tlearn: 1.1282709\ttotal: 22s\tremaining: 1m 26s\n",
      "200:\tlearn: 0.9498708\ttotal: 44.8s\tremaining: 1m 6s\n",
      "300:\tlearn: 0.8485630\ttotal: 1m 6s\tremaining: 43.9s\n",
      "400:\tlearn: 0.7854087\ttotal: 1m 28s\tremaining: 21.8s\n",
      "499:\tlearn: 0.7340948\ttotal: 1m 49s\tremaining: 0us\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "0:\tlearn: 21.8156919\ttotal: 398ms\tremaining: 3m 18s\n",
      "100:\tlearn: 1.3289755\ttotal: 40.2s\tremaining: 2m 38s\n",
      "200:\tlearn: 1.1125324\ttotal: 1m\tremaining: 1m 30s\n",
      "300:\tlearn: 1.0034519\ttotal: 1m 21s\tremaining: 54.1s\n",
      "400:\tlearn: 0.9308620\ttotal: 1m 43s\tremaining: 25.5s\n",
      "499:\tlearn: 0.8797351\ttotal: 2m 4s\tremaining: 0us\n",
      "[CV] END depth=8, iterations=500, l2_leaf_reg=7, learning_rate=0.05, random_strength=2; total time= 2.3min\n",
      "0:\tlearn: 62.2017296\ttotal: 153ms\tremaining: 15.1s\n",
      "99:\tlearn: 3.5942082\ttotal: 17.2s\tremaining: 0us\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=7, learning_rate=0.1, random_strength=1; total time=  31.8s\n",
      "0:\tlearn: 62.2514695\ttotal: 373ms\tremaining: 3m 6s\n",
      "100:\tlearn: 3.3091790\ttotal: 34.8s\tremaining: 2m 17s\n",
      "200:\tlearn: 2.7826998\ttotal: 1m 9s\tremaining: 1m 42s\n",
      "300:\tlearn: 2.5111219\ttotal: 1m 42s\tremaining: 1m 7s\n",
      "400:\tlearn: 2.2573426\ttotal: 2m 15s\tremaining: 33.6s\n",
      "499:\tlearn: 2.1114394\ttotal: 2m 48s\tremaining: 0us\n",
      "[CV] END depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.1, random_strength=5; total time= 3.1min\n",
      "0:\tlearn: 62.2075315\ttotal: 184ms\tremaining: 18.2s\n",
      "99:\tlearn: 3.6423891\ttotal: 16.3s\tremaining: 0us\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=3, learning_rate=0.1, random_strength=1; total time=  31.5s\n",
      "0:\tlearn: 62.0626155\ttotal: 441ms\tremaining: 3m 39s\n",
      "100:\tlearn: 2.7737672\ttotal: 45.6s\tremaining: 3m\n",
      "200:\tlearn: 2.2355531\ttotal: 1m 30s\tremaining: 2m 14s\n",
      "300:\tlearn: 1.9149690\ttotal: 2m 15s\tremaining: 1m 29s\n",
      "400:\tlearn: 1.6742046\ttotal: 2m 55s\tremaining: 43.4s\n",
      "499:\tlearn: 1.5090314\ttotal: 3m 40s\tremaining: 0us\n",
      "[CV] END depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.1, random_strength=2; total time= 4.0min\n",
      "0:\tlearn: 62.2010721\ttotal: 233ms\tremaining: 23.1s\n",
      "99:\tlearn: 3.5823487\ttotal: 16.6s\tremaining: 0us\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=3, learning_rate=0.1, random_strength=1; total time=  31.9s\n",
      "0:\tlearn: 62.0507245\ttotal: 315ms\tremaining: 2m 37s\n",
      "100:\tlearn: 2.8904068\ttotal: 45.9s\tremaining: 3m 1s\n",
      "200:\tlearn: 2.3511039\ttotal: 1m 31s\tremaining: 2m 16s\n",
      "300:\tlearn: 2.0452949\ttotal: 2m 16s\tremaining: 1m 30s\n",
      "400:\tlearn: 1.8481265\ttotal: 2m 57s\tremaining: 43.7s\n",
      "499:\tlearn: 1.6706793\ttotal: 3m 41s\tremaining: 0us\n",
      "[CV] END depth=8, iterations=500, l2_leaf_reg=5, learning_rate=0.1, random_strength=2; total time= 4.0min\n",
      "0:\tlearn: 21.8170759\ttotal: 537ms\tremaining: 4m 28s\n",
      "100:\tlearn: 1.3738811\ttotal: 39.9s\tremaining: 2m 37s\n",
      "200:\tlearn: 1.1370995\ttotal: 1m 1s\tremaining: 1m 31s\n",
      "300:\tlearn: 1.0194582\ttotal: 1m 22s\tremaining: 54.7s\n",
      "400:\tlearn: 0.9202041\ttotal: 1m 43s\tremaining: 25.6s\n",
      "499:\tlearn: 0.8574339\ttotal: 2m 4s\tremaining: 0us\n",
      "[CV] END depth=8, iterations=500, l2_leaf_reg=7, learning_rate=0.05, random_strength=2; total time= 2.3min\n",
      "0:\tlearn: 62.2082005\ttotal: 165ms\tremaining: 16.3s\n",
      "99:\tlearn: 3.6326283\ttotal: 16.8s\tremaining: 0us\n",
      "[CV] END depth=4, iterations=100, l2_leaf_reg=7, learning_rate=0.1, random_strength=1; total time=  31.2s\n",
      "0:\tlearn: 62.2521471\ttotal: 252ms\tremaining: 2m 5s\n",
      "100:\tlearn: 3.2977395\ttotal: 33.9s\tremaining: 2m 13s\n",
      "200:\tlearn: 2.7369590\ttotal: 1m 6s\tremaining: 1m 39s\n",
      "300:\tlearn: 2.4451309\ttotal: 1m 40s\tremaining: 1m 6s\n",
      "400:\tlearn: 2.2326452\ttotal: 2m 14s\tremaining: 33.2s\n",
      "499:\tlearn: 2.0835106\ttotal: 2m 47s\tremaining: 0us\n",
      "[CV] END depth=6, iterations=500, l2_leaf_reg=5, learning_rate=0.1, random_strength=5; total time= 3.1min\n",
      "0:\tlearn: 65.4058381\ttotal: 754ms\tremaining: 6m 16s\n",
      "100:\tlearn: 3.3687329\ttotal: 44.3s\tremaining: 2m 54s\n",
      "200:\tlearn: 2.7924520\ttotal: 1m 5s\tremaining: 1m 37s\n",
      "300:\tlearn: 2.4814640\ttotal: 1m 26s\tremaining: 56.9s\n",
      "400:\tlearn: 2.2714455\ttotal: 1m 47s\tremaining: 26.5s\n",
      "499:\tlearn: 2.1014660\ttotal: 2m 8s\tremaining: 0us\n",
      "[CV] END depth=8, iterations=500, l2_leaf_reg=7, learning_rate=0.05, random_strength=2; total time= 2.4min\n",
      "0:\tlearn: 62.0317985\ttotal: 265ms\tremaining: 2m 12s\n",
      "100:\tlearn: 2.8158105\ttotal: 22.3s\tremaining: 1m 28s\n",
      "200:\tlearn: 2.3593679\ttotal: 44.8s\tremaining: 1m 6s\n",
      "300:\tlearn: 2.1159270\ttotal: 1m 6s\tremaining: 44.1s\n",
      "400:\tlearn: 1.9459222\ttotal: 1m 27s\tremaining: 21.7s\n",
      "499:\tlearn: 1.7861210\ttotal: 1m 50s\tremaining: 0us\n",
      "Best parameters for longitude prediction: {'random_strength': 2, 'learning_rate': 0.1, 'l2_leaf_reg': 5, 'iterations': 500, 'depth': 8}\n",
      "0:\tlearn: 62.0317985\ttotal: 263ms\tremaining: 2m 11s\n",
      "100:\tlearn: 2.8158105\ttotal: 22.7s\tremaining: 1m 29s\n",
      "200:\tlearn: 2.3593679\ttotal: 45s\tremaining: 1m 6s\n",
      "300:\tlearn: 2.1159270\ttotal: 1m 7s\tremaining: 44.4s\n",
      "400:\tlearn: 1.9459222\ttotal: 1m 28s\tremaining: 21.8s\n",
      "499:\tlearn: 1.7861210\ttotal: 1m 50s\tremaining: 0us\n",
      "CatBoost Latitude Prediction Results:\n",
      "Mean Squared Error (MSE): 0.8135\n",
      "Mean Absolute Error (MAE): 0.1833\n",
      "R^2 Score: 0.9984\n",
      "CatBoost Longitude Prediction Results:\n",
      "Mean Squared Error (MSE): 5.5948\n",
      "Mean Absolute Error (MAE): 0.4164\n",
      "R^2 Score: 0.9988\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "y_lat = trainCatB[\"latitude\"].copy()\n",
    "y_lon = trainCatB[\"longitude\"].copy()\n",
    "\n",
    "X = trainCatB.drop(columns=['latitude', 'longitude', 'etaRaw', 'portId', 'cog', 'sog', 'rot', 'heading'])\n",
    "\n",
    "X[\"time\"] = pd.to_numeric(X[\"time\"], errors='coerce')\n",
    "\n",
    "X = pd.get_dummies(X, columns=[\"navstat\"], prefix=\"\", prefix_sep=\"\")\n",
    "X.rename(columns={\"0\": \"Under_Way\", \"1\": \"Anchored\", \"5\": \"Moored\"}, inplace=True)\n",
    "X = X.drop(columns=[\"15\"])\n",
    "\n",
    "X[\"avgSOG\"] = X[\"vesselId\"].apply(lambda x: avg.get(x))\n",
    "X[\"vesselId\"] = X[\"vesselId\"].map(vessel_dict)\n",
    "\n",
    "X_train_lat, X_test_lat, y_train_lat, y_test_lat = train_test_split(X, y_lat, test_size=0.2, random_state=42)\n",
    "X_train_lon, X_test_lon, y_train_lon, y_test_lon = train_test_split(X, y_lon, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize CatBoost Regressor with default parameters\n",
    "categorical_features = ['vesselId', 'Under_Way', 'Anchored', 'Moored']\n",
    "catboost_lat = CatBoostRegressor(loss_function='RMSE', cat_features=categorical_features, verbose=100)\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_distributions = {\n",
    "    'iterations': [100, 200, 500],\n",
    "    'depth': [4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'l2_leaf_reg': [3, 5, 7],\n",
    "    'random_strength': [1, 2, 5]\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning with GridSearchCV for latitude\n",
    "random_search_lat = RandomizedSearchCV(estimator=catboost_lat, param_distributions=param_distributions, n_iter=5, cv=2, n_jobs=-1, verbose=2, random_state=42)\n",
    "random_search_lat.fit(X_train_lat, y_train_lat)\n",
    "best_params_lat = random_search_lat.best_params_\n",
    "print(f\"Best parameters for latitude prediction: {best_params_lat}\")\n",
    "\n",
    "# Train the CatBoost model using the best parameters for latitude\n",
    "catboost_lat_best = CatBoostRegressor(cat_features=categorical_features, **best_params_lat, verbose=100)\n",
    "catboost_lat_best.fit(X_train_lat, y_train_lat)\n",
    "\n",
    "# Hyperparameter tuning with GridSearchCV for longitude\n",
    "catboost_lon = CatBoostRegressor(loss_function='RMSE', cat_features=categorical_features, verbose=100)\n",
    "random_search_lon = RandomizedSearchCV(estimator=catboost_lon, param_distributions=param_distributions, n_iter=5, cv=2, n_jobs=-1, verbose=2, random_state=42)\n",
    "random_search_lon.fit(X_train_lon, y_train_lon)\n",
    "best_params_lon = random_search_lon.best_params_\n",
    "print(f\"Best parameters for longitude prediction: {best_params_lon}\")\n",
    "\n",
    "# Train the CatBoost model using the best parameters for longitude\n",
    "catboost_lon_best = CatBoostRegressor(cat_features=categorical_features, **best_params_lon, verbose=100)\n",
    "catboost_lon_best.fit(X_train_lon, y_train_lon)\n",
    "\n",
    "# Step 7: Evaluate the models\n",
    "def evaluate_result(y_test, y_pred):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "    print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
    "    print(f'R^2 Score: {r2:.4f}')\n",
    "\n",
    "# Latitude predictions\n",
    "y_pred_lat = catboost_lat_best.predict(X_test_lat)\n",
    "print('CatBoost Latitude Prediction Results:')\n",
    "evaluate_result(y_test_lat, y_pred_lat)\n",
    "\n",
    "# Longitude predictions\n",
    "y_pred_lon = catboost_lon_best.predict(X_test_lon)\n",
    "print('CatBoost Longitude Prediction Results:')\n",
    "evaluate_result(y_test_lon, y_pred_lon)\n",
    "\n",
    "test = testCatB.drop(columns=['ID', 'scaling_factor'])\n",
    "\n",
    "test[\"vesselId\"] = test[\"vesselId\"].map(vessel_dict)\n",
    "test = updateNavStat(X, test, schedulesdf)\n",
    "\n",
    "test[\"avgSOG\"] = test[\"vesselId\"].apply(lambda x: avg.get(x))\n",
    "test[\"time\"] = pd.to_numeric(test[\"time\"], errors='coerce')\n",
    "\n",
    "cols = test.columns.tolist()\n",
    "time_index = cols.index('time')\n",
    "vesselId_index = cols.index('vesselId')\n",
    "cols[time_index], cols[vesselId_index] = cols[vesselId_index], cols[time_index]\n",
    "test = test[cols]\n",
    "\n",
    "# Step 8: Final predictions on test set and submission creation\n",
    "lat_pred = catboost_lat_best.predict(test)\n",
    "lon_pred = catboost_lon_best.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddcc7714-7e51-462f-90b2-51af8f364442",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>longitude_predicted</th>\n",
       "      <th>latitude_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-80.618599</td>\n",
       "      <td>31.485052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>120.428808</td>\n",
       "      <td>14.996091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10.884976</td>\n",
       "      <td>38.740143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>172.958424</td>\n",
       "      <td>-42.062873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-6.006832</td>\n",
       "      <td>49.086967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51734</th>\n",
       "      <td>51734</td>\n",
       "      <td>-49.098934</td>\n",
       "      <td>32.982273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51735</th>\n",
       "      <td>51735</td>\n",
       "      <td>-67.317577</td>\n",
       "      <td>29.405737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51736</th>\n",
       "      <td>51736</td>\n",
       "      <td>-137.460310</td>\n",
       "      <td>26.761694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51737</th>\n",
       "      <td>51737</td>\n",
       "      <td>10.961628</td>\n",
       "      <td>51.858896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51738</th>\n",
       "      <td>51738</td>\n",
       "      <td>11.969402</td>\n",
       "      <td>55.880117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51739 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  longitude_predicted  latitude_predicted\n",
       "0          0           -80.618599           31.485052\n",
       "1          1           120.428808           14.996091\n",
       "2          2            10.884976           38.740143\n",
       "3          3           172.958424          -42.062873\n",
       "4          4            -6.006832           49.086967\n",
       "...      ...                  ...                 ...\n",
       "51734  51734           -49.098934           32.982273\n",
       "51735  51735           -67.317577           29.405737\n",
       "51736  51736          -137.460310           26.761694\n",
       "51737  51737            10.961628           51.858896\n",
       "51738  51738            11.969402           55.880117\n",
       "\n",
       "[51739 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 65.3951342\ttotal: 586ms\tremaining: 4m 52s\n",
      "100:\tlearn: 3.4421365\ttotal: 39.6s\tremaining: 2m 36s\n",
      "200:\tlearn: 2.8676606\ttotal: 1m 1s\tremaining: 1m 31s\n",
      "300:\tlearn: 2.5646921\ttotal: 1m 23s\tremaining: 55.1s\n",
      "400:\tlearn: 2.3482048\ttotal: 1m 44s\tremaining: 25.8s\n",
      "499:\tlearn: 2.1587949\ttotal: 2m 4s\tremaining: 0us\n",
      "[CV] END depth=8, iterations=500, l2_leaf_reg=7, learning_rate=0.05, random_strength=2; total time= 2.4min\n"
     ]
    }
   ],
   "source": [
    "submission(sampledf, lat_pred, lon_pred, True, \"catboost_prediction_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0564effc-1330-4652-ad3e-264eee295991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cpu:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
